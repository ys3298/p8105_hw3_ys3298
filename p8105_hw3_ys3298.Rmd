---
title: "p8105_hw3_ys3298"
author: "Yimeng SHANG"
date: "10/3/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.height = 6,
	fig.width = 8,
	warning = FALSE,
	out.width = "90%"
)
```

```{r echo=TRUE}
library(p8105.datasets)
library(tidyverse)
library(patchwork)
data("instacart")
data("brfss_smart2010")
accel = read_csv("./data/accel_data.csv") 
```

```{r echo=TRUE}
aisle_num =
  instacart %>%
  group_by(aisle) %>%
  summarise(number = n()) %>%
  count() %>%
  as.integer()
aisle_num 

aisle_max = 
  instacart %>%
  group_by(aisle) %>%
  summarise(number = n()) %>%
  filter(number == max(number)) %>%
  select(-number) %>%
  as.character()
aisle_max
```
# Problem1
## Short description
**The size and structure of the data:** There are `r nrow(instacart)` observations and `r ncol(instacart)` variables in the data. It's a (`r dim(instacart)`) dataframe. Most of the variable types are integers and some are characters. 

**Some key variables:** Product name; aisle; department; order number and so on. 

**illstrative examples of observations:** For the 1st order, there're 8 different kind of products. Eval set is train. In details, the first product is `r instacart[1,11]`, aisle id is `r instacart[1,12]`, department id is `r instacart[1,13]`, aisle is `r instacart[1,14]`, department is `r instacart[1,15]`. For the second observations, aisle id is `r instacart[2,12]`, department id is `r instacart[2,13]`, aisle is `r instacart[2,14]`, department is `r instacart[2,15]` .

**How many aisles are there, and which aisles are the most items ordered from?** There are `r aisle_num` aisles. The most items ordered from `r aisle_max`. comment: the order from different aisles are very different, vegetable is the most and then fresh fruit.

## Make a plot
```{r echo=TRUE}
  instacart %>%
  group_by(aisle) %>%
  summarise(number = n()) %>%
  filter(number > 10000) %>%
  ggplot(aes(x = reorder(aisle, number), y = number, fill = aisle)) +
  geom_col() + coord_flip() +
  viridis::scale_fill_viridis(option = "viridis" , discrete = TRUE) +
  labs(
    title = "The number of items ordered in each Aisle",
    x = "aisles",
    y = "number"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

Comment: From the plot, we can clearly see the rank of number of items ordered in each aisle. The orders from fresh vegetables are the most and  butter is the least within those whose order is more than 10000.

## Table1: most popular items in each aisles
```{r echo=TRUE}
baking = 
  instacart %>%
  group_by(product_name) %>%
  filter(aisle == "baking ingredients") %>%
  summarise(order_times = n()) %>%
  arrange(desc(order_times)) %>%
  head(n = 3) %>%
  mutate(group = "baking ingredients") %>%
  select(group, everything())

dog = 
  instacart %>%
  group_by(product_name) %>%
  filter(aisle == "dog food care") %>%
  summarise(order_times = n()) %>%
  arrange(desc(order_times)) %>%
  head(n = 3) %>%
  mutate(group = "dog food care") %>%
  select(group, everything())

vege =
  instacart %>%
  group_by(product_name) %>%
  filter(aisle == "packaged vegetables fruits") %>%
  summarise(order_times = n()) %>%
  arrange(desc(order_times)) %>%
  head(n = 3) %>%
  mutate(group = "packaged vegetables fruits") %>%
  select(group, everything())

bind_rows(baking, dog, vege) %>%
  knitr::kable(caption="top3 popular items in specific aisles")
```

Comment: From the table, the most popular items from baking ingredients are cane sugar, light brown sugar and pure baking soda. In the group of dog food care, organix chicken&brown rice recipe, small dog biscuits, snack sticks chicken & rice recipe dog treats are the top3 popular items. And in the group of packaged vegetables fruits, organic baby spinach, organic blueberries, organic raspverries sells best.

## Table2: mean hour of a day ordered on each day
```{r echo=TRUE}
instacart %>%
  select(product_name, order_hour_of_day, order_dow) %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>%
  group_by(product_name, order_dow) %>%
  summarise(
    mean_hour = mean(order_hour_of_day)
  ) %>%
  mutate(
    mean_hour = round(mean_hour,1),
    order_dow = recode(order_dow, "0" = "Sun", "1" = "Mon", "2" = "Tue", "3" = "Wed", "4" = "Thur", "5" = "Fri", "6" = "Sat")
  ) %>%
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hour"
  ) %>%  
  knitr::kable(caption="Mean hour of a day ordered on each day")
```

Comment: From this table, we can clearly see the mean hour of the day at which pink lady apples and coffee ice cream are ordered on each day of the week. Coffee ice cream is ordered most on Tuesday and least on Friday.

# Problem2
```{r echo=TRUE}
##cleaning
  brfss_OH =
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE )
  )
brfss_OH
```

```{r echo=TRUE}
location2002 =
  brfss_OH %>%
  filter(year ==  "2002") %>%
  group_by(locationabbr) %>%
  distinct(locationdesc) %>%
  summarise(total_location = n()) %>%
  filter(total_location >= 7) %>%
  arrange(total_location)
location2002

location2010 =
  brfss_OH %>%
  filter(year ==  "2010") %>%
  group_by(locationabbr) %>%
  distinct(locationdesc) %>%
  summarise(total_location = n()) %>%
  filter(total_location >= 7) %>%
  arrange(total_location)
location2010 
```
Comment: In 2002, `r location2002$locationabbr` were observed at 7 or more locations. Total: `r length(location2002$locationabbr)`

In 2010, `r location2010$locationabbr` were observed at 7 or more locations. Total: `r length(location2010$locationabbr)`

It's more in 2010 than 2002.

```{r echo=TRUE}
Averagedf =
  brfss_OH %>%
  filter(response == "Excellent") %>%
  group_by(locationabbr, year) %>%
  summarise(average = mean(data_value)) %>%
  select(year, locationabbr, average)


  brfss_OH %>%
  filter(response == "Excellent") %>%
  group_by(locationabbr, year) %>%
  summarise(average = mean(data_value)) %>%
  select(year, locationabbr, average) %>%
  ggplot(aes(x = year, y = average, color = locationabbr, group = locationabbr)) +
  geom_line() + 
    labs(
      title = "averages the data_value across locations limited to Excellent responses",
      x = "Year",
      y = "Average data value"
    ) +
  viridis::scale_color_viridis(
    name = "States",
    discrete = TRUE) +
    theme(plot.title = element_text(hjust = 0.5))
```

Comment: This figure has so many states information, so it's not so clearly to see. We notice that most of the states fluctuate from 2002 to 2010. Also, I do notice that there're a few NAs after take the average(I don't think it's necessary to drop them).

```{r eval=FALSE, include=FALSE}
#(don't choose this plot at last so did't run this part)
plot2006 =  brfss_OH %>%
  filter(locationabbr == "NY" & year == "2006" ) %>%
  select(locationdesc, response, data_value) %>%
  ggplot(aes(x = locationdesc, y = data_value, color = response, group = response)) +
  geom_point(size = 4, alpha = .5) + geom_line() +
  labs(
      title = "Response Plot for 2006",
      x = "Location",
      y = "data value"
    ) +
  viridis::scale_color_viridis(
    name = "Location",
    discrete = TRUE) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom", axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))


plot2010 =  brfss_OH %>%
  filter(locationabbr == "NY" & year == "2010" ) %>%
  select(locationdesc, response, data_value) %>%
  ggplot(aes(x = locationdesc, y = data_value, color = response, group = response)) +
  geom_point(size = 4, alpha = .5) + geom_line() +
  labs(
      title = "Response Plot for 2010",
      x = "Location",
      y = "data value"
    ) +
  viridis::scale_color_viridis(
    name = "Location",
    discrete = TRUE) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom", axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))
 
plot2006 + plot2010 
```


```{r echo=FALSE, warning=TRUE}
brfss_OH  %>% 
  filter(year == "2006" | year == "2010" ) %>% 
  filter(locationabbr == "NY") %>% 
  ggplot(aes(x = response, y = data_value,fill = locationdesc)) +
  geom_line(aes(group = locationdesc, color = locationdesc)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_point(size = 2, alpha = 0.5) +
  labs(
    title = " Data value of NY"
  ) +
  facet_grid(~year)
```
Comment: From the Plot, we can see the distribution of data value for reponses among locations. "Poor" was the lowest and "Very good" and "Excellent" and relatively high. There is difference in different locations. Form 2006 to 2010, the distribution changed a little bit, but the whole distribution is similar. Or we can also use boxplot as following:
```{r echo=TRUE}
brfss_OH  %>% 
  filter(year == "2006" | year == "2010" ) %>% 
  filter(locationabbr == "NY") %>% 
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  facet_grid(~year)

```



# Problem3
```{r echo=TRUE}
accel = 
  accel %>%
  janitor::clean_names() %>% 
  mutate(day = ordered(day, levels=c("Monday", "Tuesday",
                      "Wednesday","Thursday","Friday","Saturday","Sunday"))) %>%
  arrange(week, day) %>%
  mutate(sorted_DayId=1:n()) %>%
  select(-day_id) %>%
  pivot_longer(cols=starts_with("activity_"), 
               names_prefix = "activity_",
               names_to="activity") %>%
  mutate(activity=as.integer(activity)) %>%
  arrange(week, day, activity) %>% 
  mutate(time=1:n()) %>%
  mutate(day_type = if_else(day<="Friday","WeekDay","WeekEnd")) %>% 
  mutate(value = round(value, 0)) %>% 
    mutate_if(is.double, as.integer)

```

Comment: I rearrange the day_id in oreder to put it into right order. For this resulting dataset, there are `r nrow(accel)` observations and `r ncol(accel)` variables. It also includes the week, day ID, weekend or weekday information. I round all activity value data into integer in order to see clearly.

## Total activity variable for each day
```{r echo=TRUE}
accel_sum = accel %>% 
  group_by(week,day,sorted_DayId,day_type) %>% 
  summarise(value=sum(value)) 
knitr::kable(accel_sum)

accel_sum %>% 
  ggplot(aes(x = day, y = value, color = week, group=week)) +
  geom_point(size = 4, alpha = .5) + geom_line() +
  labs(
     title = "sum for each day",
      x = "day",
      y = "sum"
    ) +
  viridis::scale_color_viridis(
    name = "week",
    discrete = FALSE) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom", axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))

```

Comment:  This table in not clear to see the trend. From the plot, we can see in week1 and week2, the sum for each day increase from Monday to Sunday, however, in week3, week4 and week5, the trends are not so aparent.
 
```{r echo=TRUE}

ggplot(accel) +
geom_line(aes(x=activity, y=value,colour=day,fill=day)) +
scale_x_continuous("hour", breaks = seq(30, 1410, 60),labels=c(1:24)) + labs(title = "activity in 24 hours")
  
```


Comment: Based on this graph, we can see the activity is relatively low at the beginning of a day, and increase. The most active periods are around 12pm and 22pm. After 22pm, the value starts to decrease. There are so many overlaps between lines and lines, so I then use geom_area to show the sum of each minite in 24 hour as following.

```{r}
ggplot(accel) +
geom_area(aes(x=activity, y=value,colour=day,fill=day)) +
scale_x_continuous("hour", breaks = seq(30, 1410, 60),labels=c(1:24)) + labs(title = "activity in 24 hours")
```
Comment: Based on this graph, we can clearly see that the highest is around 22pm and then 12pm(two peaks), it means that the sum of all activities in this time for all day is the most. The lowest is from 24pm to 5am , it means that the sum of all activities in this time for all day is the least. And the activity on Monday is the most.

```{r eval=FALSE, include=FALSE}
## another optional choice (not so good, didn't run and show)
ggplot(accel) + geom_linerange(aes(x=time,ymax=value,ymin=0,colour=day)) + scale_x_continuous("weeks", breaks = seq(5040, 50400 - 5040, 1440*7),labels=c(1:5)) + labs(title = "activity for every day") +   viridis::scale_color_viridis(
    name = "week",
    discrete = TRUE) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom")
```
